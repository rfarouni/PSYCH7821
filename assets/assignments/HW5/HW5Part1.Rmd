---
title: "HW5 Part 1"
author: "Rick Farouni"
date: "November 29, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Question 1 (Factor Analysis)

When we fit a factor analysis model, we usually assume that there are fewer factors than we have indicators (e.g. tests). For example, we can infer the existence of a hypothetical construct such as a general factor of intelligence from the explained shared variance in several ability tests (e.g. verbal, quantitative, spatial, memory). 

For this exercise, I ask you to indulge me by assuming the opposite, that there are more factors than we have indicators! In his 1916 paper "hierarchy without a general factor", the English educational psychologist Godfrey Thomson introduced exactly such a model. More specifically,  assume that each test is actually a linear combination of a great number of latent ability traits that we didn’t actually measure. 

The data you will be using for this question has been simulated from model based on Thomson's sampling model. For concreteness, consider the following scenario: Imagine a human population that possesses 550 distinct and independent mental abilities (latent traits). The abilities are normally distributed among its members (an individual's profile is a point in this 550 dimensional space). We administer 10 tests to a sample of 50 test takers from this population. The data we collect is a 50 x 10 matrix, which you can find in the file "ThomsonData.csv".

The simulation assumes that each test is a combination of general and specific ability traits. The general ability for each test is linear combination of a random subset of 500 of the 550 traits. These 500 traits are shared among the ten test, so for example, the general ability component of Test 1 could be a linear combination of Trait1, Trait 33, …, Trait 200  whereas for Test 2 it can be a linear combination of Trait 10, Trait 33, … , Trait 200. The specific ability component is specific to each test only.

### Question 1a  

Specify a model with a single factor (check lavaan syntax for an example). Note that the variables in the dataset are named ("test1" , "test2" , "test3" ,"test4" , "test5" , "test6" ,"test7" , "test8" , "test9", "test10")

### Question 1b

Read the data and fit the specified model with a standardized latent variable. Provide two matrices: the standardized loadings and residuals.

 
### Question 1c

When assesing model fit you can compare the fit of your model to 

1. No model at all by using an **absolute fit index** 
2. To the null/independence model that assumes that the indicators are uncorrelated by using an **incremental fit index**  
3. The difference between what is observed an what is predicted using an index based on residuals. 

Many researchers have recommended reporting several fit indicies to assess model fit. The three most recommended (with suggested cutoffs) are 

1. The SRMR (< 0.09)
2. The RMSEA ( < 0.06)
3. The CFI  (> 0.96)

Please provide the model fit measures for these three indicies.


### Question 1d

Which of these three indicies is an absolute,  incremental, or a residual-based fit index? Name one property of each index that makes it better than other fit measures in its class (you can do web search).

### Question 1e

What is the null hypothesis? Given the values of the model fit indicies, do you reject the null? Is a single factor model a good fit for the data?


### Question 1f

Model fit provides little information about how the data was actually generated. Which model, Spearman's general factor approach or Thomson's model, is more plausible in real world applications in psychology, educational testing, marketing, or other fields that rely on surveys and self-report data?


### Question 1g

True or False: Thomson is a good example of the proverbial prophet crying in the wilderness.

