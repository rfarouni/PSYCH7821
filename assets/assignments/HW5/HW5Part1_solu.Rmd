---
title: "HW5 Part 1"
author: "Rick Farouni"
date: "November 29, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1 (Factor Analysis)

When we fit a factor analysis model, we usually assume that there are fewer factors than we have indicators (e.g. tests). For example, we can infer the existence of a hypothetical construct, a general factor of intelligence, from the explained shared variance in several ability tests (i.e. verbal, quantitative, spatial, memory). 

For this exercise, I ask you to indulge me in assuming the opposite. That there are more factors than we have indicators! More specifically, that each test is actually a linear combination of a great number of latent ability traits we didnâ€™t measure. In his 1916 aper "hierarchy without a general factor", the English educational psychologist Godfrey Thomson introduced exactly such a model. The data you will be using for this question has been simulated from model based on Thomson's sampling model. For concreteness, consider the following scenario:

Imagine a human population that possesses 550 distinct and independent mental abilities (latent traits). The abilities are normally distributed among its members (an individual's profile is a point in this 550 dimensional space). We administer 10 tests to a sample of 50 test takers from this population. The data we collect is a 50 x 10 matrix, which you can find in the file "ThomsonData.csv"

The simulatation assumes that each test is a combination of general and specific ability traits. The general ability for each test is linear combination of a random subset of 500 of the 550 traits. These 500 traits are shared among the ten test, so for example, the general ability component of Test1 could be a linear combination of Trait1, Trait 33, and Trait 200 whereas for Test2 it can be a linear combination of Trait 10, Trait 33, and Trait 200. The specific ability component is specific to each test only.

### Question 1a  

Specify a model with a single factor (check lavaan syntax for an example). Note that the variables in the dataset are named ("test1" , "test2" , "test3" ,"test4" , "test5" , "test6" ,"test7" , "test8" , "test9", "test10")

### Solution 1a  

The model specification for mean centered data is

$$\begin{aligned}
\mathbf y_i &=\boldsymbol \Lambda \boldsymbol \eta_i + \boldsymbol \epsilon_i \\
or \ expanded \ as \ \begin{bmatrix}
y_{i,1} \\ 
\vdots\\ 
y_{i,10}
\end{bmatrix} &=
\begin{bmatrix} 
\lambda_1\\
\vdots\\
\lambda_{10}
\end{bmatrix}
\begin{bmatrix} 
\eta_i
\end{bmatrix}
+
\begin{bmatrix} 
\epsilon_{i,1} \\ 
\vdots\\ 
\epsilon_{i,10}
\end{bmatrix}\\
where \ Cov(\boldsymbol \epsilon_i) = \boldsymbol \Theta=&\begin{bmatrix}
  \sigma^2_1 & 0  & \ldots & 0  \\
   0 & \sigma^2_2  & \ldots & 0  \\
 \vdots &\vdots &  \ddots  & \vdots \\
0 & \ldots  & 0 &\sigma^2_p
\end{bmatrix}, \\
\ Cov(\boldsymbol \eta_i) = \boldsymbol \Psi =& \begin{bmatrix} 
1
\end{bmatrix}, \ \boldsymbol \epsilon_i \perp \boldsymbol \eta_i,   \ \  for \   i=1, ..., 50. 
\end{aligned} 
$$
The covariance structure form of the model for the population is 
$$
\boldsymbol \Sigma= \boldsymbol\Lambda\boldsymbol \Psi \boldsymbol\Lambda^{T} +  \boldsymbol \Theta
$$
In *lavaan* the model can be specified as shown below if the *cfa* function is used. The *cfa* function takes care of the above-mentioned assumptions under the hood.
```{r}
fa_model <- 'f1 =~ test1+ test2 + test3 + test4 + test5 + test6 + test7+ test8 + test9 + test10'

```
### Question 1b

Read the data and fit the specified model with a standardized latent variable. Provide the standardized parameters and residuals.

### Solution 1b  

```{r, message=FALSE}
library(lavaan)

df <- read.csv("ThomsonData.csv")
fa_model_fit <- cfa(model = fa_model,
                    data = df, 
                    std.lv = TRUE)
lavInspect(fa_model_fit, "std")
```
```{r}
residuals(fa_model_fit)
```
 
### Question 1c

When assesing model fit you can compare the fit of your model to 

1. No model at all by using an **absolute fit index** 
2. To the null/independence model that assumes that the indicators are uncorrelated by using an **incremental fit index**  
3. The difference between what is observed an what is predicted using an index based on residuals. 

Many researchers have recommended reporting several fit indicies to assess model fit. The three most recommended (with suggested cutoffs) are 

1. The SRMR (< 0.09)
2. The RMSEA ( < 0.06)
3. The CFI  (> 0.96)

Please provide the model fit measures for these three indicies.

### Solution 1c  


```{r}
fitMeasures(fa_model_fit, c("srmr", "rmsea", "cfi"))
```

### Question 1d

Which of these three indicies is an abolute, an incremental, or a residual based fit index? Name one property of each index that makes it better than other fit measures in its class (you can do web search).

### Solution 1d

 1. The RMSEA is an absolute measure of fit. It imporves on the chi-squared test statistics. Whereas the chi-squared test statistics is
 very sensitive to the sample size and also to deviations from normality, the RMSEA is more robust in that it assumes a model that holds approximately in the population.

 2. The CFI is an incremental measure of fit.  It calculates the incremental improvement in the fit of the model compared to independence model that assumes that the observed variables are uncorrelated. It is an improvement over the Normed-fit index (NFI) in that it takes sample size into account. 
 
3. The SRMR is the standardised measure of the average covariance residuals, which are the differences between the sample covariance matrix and the estimated
covariance matrix assumed under the correct model. The SRMR improves upon the RMR, which is an unstandardized measure that depends on the scale of the variables and is therefore difficult to interpret.


```{r}
summary(fa_model_fit , fit.measures = TRUE)
```



### Question 1e

What is the null hypothesis? Given the values of the model fit indicies, do you reject the null? Is a single factor model a good fit for the data?

### Solution 1e

The likelihood ratio statistic of our model assumes that null hypothesis is 
$$
\begin{aligned}
H_0:\boldsymbol \Sigma= \boldsymbol\Lambda\boldsymbol \Lambda^{T} +  \boldsymbol \Theta &=\begin{bmatrix} 
\lambda_1\\
\vdots\\
\lambda_{10}
\end{bmatrix} \begin{bmatrix} 
\lambda_1
\cdots\
\lambda_{10}
\end{bmatrix} +  \begin{bmatrix}
  \sigma^2_1 & 0  & \ldots & 0  \\
   0 & \sigma^2_2  & \ldots & 0  \\
 \vdots &\vdots &  \ddots  & \vdots \\
0 & \ldots  & 0 &\sigma^2_{10}
\end{bmatrix} \\ &= \begin{bmatrix}
  \lambda_1^2+\sigma^2_1 & \lambda_1\lambda_2  & \ldots & \lambda_1\lambda_{10}  \\
   \lambda_2\lambda_1 & \lambda^2_2+\sigma^2_{2}  & \ldots & \lambda_2\lambda_{10}  \\
 \vdots &\vdots &  \ddots  & \vdots \\
\lambda_{10}\lambda_{1} & \ldots  & \lambda_{10}\lambda_{9} & \lambda^2_{10}+ \sigma^2_{10}
\end{bmatrix} 
\end{aligned} 
$$
and that the alternative hypothesis is 
$$
H_1:\boldsymbol \Sigma= \begin{bmatrix}
  \sigma_{11} & \sigma_{12} & \ldots & \sigma_{1,10}  \\
   \sigma_{21} & \sigma_{22}  & \ldots & \sigma_{2,10}  \\
 \vdots &\vdots &  \ddots  & \vdots \\
\sigma_{10,1} & \ldots  & \sigma_{10,9} &\sigma_{10,10}
\end{bmatrix}
$$
That is, the covariance matrix is unconstrained. The fit indices show an almost perfect fit to the data. **We fail to reject the null hypothesis**. There is evidence that the  sample covariance matrix of our data can have the decomposition implied by the null hypothesis. 


For incremental fit indicies, you have a set of nested sequence of hypothesis. One one end of the extreme, you have the the null/independence model that states the observed variables are uncorrelated. In this case, we say that for estimated covariance matrix  $ \hat{\Sigma}$ and sample covariance data $S$

$$
 \hat{\Sigma}= \begin{bmatrix}
  s_{11} & 0  & \ldots & 0  \\
   0 & s_{22}  & \ldots & 0  \\
 \vdots &\vdots &  \ddots  & \vdots \\
0 & \ldots  & 0 &s_{10,10}
\end{bmatrix}
$$

at the other end of the extreme, we have the saturated model

$$
\hat{\Sigma}= S=\begin{bmatrix}
  s_{11} & s_{12} & \ldots & s_{1,10}  \\
   s_{21} & s_{22}  & \ldots & s_{2,10}  \\
 \vdots &\vdots &  \ddots  & \vdots \\
s_{10,1} & \ldots  & s_{10,9} &s_{10,10}
\end{bmatrix}
$$
A incremental fit statistic value close to 0 implies that the proposed model is not an improvment over the independence model. A value close to 1 implies that the proposed model is a perfect fit for the data $S$

### Question 1f

Model fit provides little information about how the data was actually generated. Which model, Spearman's general factor approach or Thomson's model, is more plausible in real world applications in psychology, educational testing, marketing, or other fields that rely on surveys and self-report data?

### Solution 1f

The perfect fit we obtained from this widely incorrect model should give you pause. Consider any single item on a self-report measure whether it is in a depression test battery or in  a survey questionnaire. How many unobserved causes (e.g. mental processes) do you think can give rise to the response? In the physical science, the causal mechanism gets elucidates as more observable variables get measured and incorporated into the modeling framework that tries to explain the phenomenon of interest. In the social and psychological sciences, these causes are unobservable and the only way to really measure them is indirectly through brain activity or other physiological proxies. Thomson's model is not a model you can fit. It assumes that you have more latent causes than you have variables. It is a more plausible sampling model of how the world is, but it is not a model you can use to fit your data to. Pearson's model is a model of how you think the world is. It can be useful since it can provide evidence for a pattern of correlations in your data. Nonetheless, interpreting  correlations in a finite sample as representing a hypothetical construct that can objectively be measured is a fallacy known in philosophy, psychometrics, and statistics as the **reification fallacy**. Also note that correlations are measures of linear association and are only applicable when the linearity assumption holds. 


### Question 1g

True or False: Thomson is a good example of the proverbial prophet crying in the wilderness.

### Solution 1g


In the wilderness, there is no one to hear you even if what you are preaching is demonstrably true. Thomson's sampling model casts serious doubts upon one aspect of Pearson's model. Namely, that a latent variable can denote a hypothetical construct such as intelligence that we can objectively measure based on correlations in a set of observed variables. That doesn't mean you cannot measure intelligence or ability on a test using test items. We do that all the time without resorting to a specific decomposition of the covariance matrix. That also doesn't mean the latent variables models are useless. In fact, they are proving to be one of the most powerful class of models in statistics in explaining patterns in the data. The criticism lies in how these models can be misused by some researchers in the social sciences, researcher who are just too eager to arrive at true understanding of complex unobservable phenomena armed only with a survey questionnaire in one hand and a point-and-click SEM software package in the other hand (on a smart-phone maybe).  Do the researchers who developed the Big five theory of personality belong to this camp? The second part of the assignment should help you decide? 

Note that the assertions made here are only targeted at the misuse of methods not at the validity of such constructs as intelligence and extroversion. These words share similar meanings among speakers of a particular language and most would agree that people do differ on these traits. 


